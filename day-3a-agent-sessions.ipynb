{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Memory Management - Part 1 - Sessions\n\n**Welcome to Day 3 of the Kaggle 5-day Agents course!**\n\nIn this notebook, you'll learn:\n\n- ‚úÖ What sessions are and how to use them in your agent\n- ‚úÖ How to build *stateful* agents with sessions and events\n- ‚úÖ How to persist sessions in a database\n- ‚úÖ Context management practices such as context compaction\n- ‚úÖ Best practices for sharing session State","metadata":{}},{"cell_type":"markdown","source":"## ‚ÄºÔ∏è Please Read\n\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"code","source":"pip install google-adk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:16:28.394744Z","iopub.execute_input":"2025-11-12T18:16:28.395054Z","iopub.status.idle":"2025-11-12T18:16:28.499571Z","shell.execute_reply.started":"2025-11-12T18:16:28.395024Z","shell.execute_reply":"2025-11-12T18:16:28.498595Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from typing import Any, Dict\n\nfrom google.adk.agents import Agent, LlmAgent\nfrom google.adk.apps.app import App, EventsCompactionConfig\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.sessions import DatabaseSessionService\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.runners import Runner\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:16:32.271138Z","iopub.execute_input":"2025-11-12T18:16:32.271502Z","iopub.status.idle":"2025-11-12T18:17:22.570348Z","shell.execute_reply.started":"2025-11-12T18:16:32.271476Z","shell.execute_reply":"2025-11-12T18:17:22.569461Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Helper functions\n\nHelper function that manages a complete conversation session, handling session\ncreation/retrieval, query processing, and response streaming. It supports\nboth single queries and multiple queries in sequence.\n\nExample:\n\n```\n>>> await run_session(runner, \"What is the capital of France?\", \"geography-session\")\n>>> await run_session(runner, [\"Hello!\", \"What's my name?\"], \"user-intro-session\")\n```","metadata":{}},{"cell_type":"code","source":"# Define helper functions that will be reused throughout the notebook\nasync def run_session(\n    runner_instance: Runner,\n    user_queries: list[str] | str = None,\n    session_name: str = \"default\",\n):\n    print(f\"\\n ### Session: {session_name}\")\n\n    # Get app name from the Runner\n    app_name = runner_instance.app_name\n\n    # Attempt to create a new session or retrieve an existing one\n    try:\n        session = await session_service.create_session(\n            app_name=app_name, user_id=USER_ID, session_id=session_name\n        )\n    except:\n        session = await session_service.get_session(\n            app_name=app_name, user_id=USER_ID, session_id=session_name\n        )\n\n    # Process queries if provided\n    if user_queries:\n        # Convert single query to list for uniform processing\n        if type(user_queries) == str:\n            user_queries = [user_queries]\n\n        # Process each query in the list sequentially\n        for query in user_queries:\n            print(f\"\\nUser > {query}\")\n\n            # Convert the query string to the ADK Content format\n            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n\n            # Stream the agent's response asynchronously\n            async for event in runner_instance.run_async(\n                user_id=USER_ID, session_id=session.id, new_message=query\n            ):\n                # Check if the event contains valid content\n                if event.content and event.content.parts:\n                    # Filter out empty or \"None\" responses before printing\n                    if (\n                        event.content.parts[0].text != \"None\"\n                        and event.content.parts[0].text\n                    ):\n                        print(f\"{MODEL_NAME} > \", event.content.parts[0].text)\n    else:\n        print(\"No queries!\")\n\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:17:33.676724Z","iopub.execute_input":"2025-11-12T18:17:33.678027Z","iopub.status.idle":"2025-11-12T18:17:33.687119Z","shell.execute_reply.started":"2025-11-12T18:17:33.677996Z","shell.execute_reply":"2025-11-12T18:17:33.686005Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.5: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:17:39.456973Z","iopub.execute_input":"2025-11-12T18:17:39.457297Z","iopub.status.idle":"2025-11-12T18:17:39.462393Z","shell.execute_reply.started":"2025-11-12T18:17:39.457272Z","shell.execute_reply":"2025-11-12T18:17:39.461196Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\n## ü§π Section 2: Session Management\n\n### 2.1 The Problem\n\nAt their core, Large Language Models are **inherently stateless**. Their awareness is confined to the information you provide in a single API call. This means an agent without proper context management will react to the current prompt without considering any previous history.\n\n**‚ùì Why does this matter?** Imagine trying to have a meaningful conversation with someone who forgets everything you've said after each sentence. That's the challenge we face with raw LLMs!\n\nIn ADK, we use `Sessions` for **short term memory management** and `Memory` for **long term memory.** In the next notebook, you'll focus on `Memory`.","metadata":{}},{"cell_type":"markdown","source":"### 2.2 What is a Session?\n\n#### **üì¶ Session**\n\nA session is a container for conversations. It encapsulates the conversation history in a chronological manner and also records all tool interactions and responses for a **single, continuous conversation**. A session is tied to a user and agent; it is not shared with other users. Similarly, a session history for an Agent is not shared with other Agents.\n\nIn ADK, a **Session** is comprised of two key components `Events` and `State`:\n\n**üìù Session.Events**:\n\n> While a session is a container for conversations, `Events` are the building blocks of a conversation.\n>\n> Example of Events:\n> - *User Input*: A message from the user (text, audio, image, etc.)\n> - *Agent Response*: The agent's reply to the user\n> - *Tool Call*: The agent's decision to use an external tool or API\n> - *Tool Output*: The data returned from a tool call, which the agent uses to continue its reasoning\n    \n\n**{} Session.State**:\n\n> `session.state` is the Agent's scratchpad, where it stores and updates dynamic details needed during the conversation. Think of it as a global `{key, value}` pair storage which is available to all subagents and tools.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/session-state-and-events.png\" width=\"320\" alt=\"Session state and events\">\n\n<!-- ```mermaid\ngraph TD\n    subgraph A[\"Agentic Application\"];\n        subgraph U[\"User\"]\n            subgraph S1[\"Session\"]\n                D1[\"Session.Events\"]\n                D2[\"Session.State\"]\n            end\n        end\n    end\n``` -->","metadata":{}},{"cell_type":"markdown","source":"### 2.3 How to manage sessions?\n\nAn agentic application can have multiple users and each user may have multiple sessions with the application.\nTo manage these sessions and events, ADK offers a **Session Manager** and **Runner**.\n\n1. **`SessionService`**: The storage layer\n   - Manages creation, storage, and retrieval of session data\n   - Different implementations for different needs (memory, database, cloud)\n\n2. **`Runner`**: The orchestration layer\n   - Manages the flow of information between user and agent\n   - Automatically maintains conversation history\n   - Handles the Context Engineering behind the scenes\n\nThink of it like this:\n\n- **Session** = A notebook üìì\n- **Events** = Individual entries in a single page üìù\n- **SessionService** = The filing cabinet storing notebooks üóÑÔ∏è\n- **Runner** = The assistant managing the conversation ü§ñ","metadata":{}},{"cell_type":"markdown","source":"### 2.4 Implementing Our First Stateful Agent\n\nLet's build our first stateful agent, that can remember and have constructive conversations. \n\nADK offers different types of sessions suitable for different needs. As a start, we'll start with a simple Session Management option (`InMemorySessionService`):","metadata":{}},{"cell_type":"code","source":"APP_NAME = \"default\"  # Application\nUSER_ID = \"default\"  # User\nSESSION = \"default\"  # Session\n\nMODEL_NAME = \"gemini-2.5-flash-lite\"\n\n\n# Step 1: Create the LLM Agent\nroot_agent = Agent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"A text chatbot\",  # Description of the agent's purpose\n)\n\n# Step 2: Set up Session Management\n# InMemorySessionService stores conversations in RAM (temporary)\nsession_service = InMemorySessionService()\n\n# Step 3: Create the Runner\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"‚úÖ Stateful agent initialized!\")\nprint(f\"   - Application: {APP_NAME}\")\nprint(f\"   - User: {USER_ID}\")\nprint(f\"   - Using: {session_service.__class__.__name__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:17:45.651221Z","iopub.execute_input":"2025-11-12T18:17:45.651543Z","iopub.status.idle":"2025-11-12T18:17:45.659796Z","shell.execute_reply.started":"2025-11-12T18:17:45.651520Z","shell.execute_reply":"2025-11-12T18:17:45.658571Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Stateful agent initialized!\n   - Application: default\n   - User: default\n   - Using: InMemorySessionService\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### 2.5 Testing Our Stateful Agent\n\nNow let's see the magic of sessions in action!","metadata":{}},{"cell_type":"code","source":"# Run a conversation with two queries in the same session\n# Notice: Both queries are part of the SAME session, so context is maintained\nawait run_session(\n    runner,\n    [\n        \"Hi, I am Adam! What is the capital of France?\",\n        \"Hello! What is my name?\",  # This time, the agent should remember!\n    ],\n    \"stateful-agentic-session\",\n)","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:17:51.152788Z","iopub.execute_input":"2025-11-12T18:17:51.153130Z","iopub.status.idle":"2025-11-12T18:17:52.539397Z","shell.execute_reply.started":"2025-11-12T18:17:51.153103Z","shell.execute_reply":"2025-11-12T18:17:52.538348Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: stateful-agentic-session\n\nUser > Hi, I am Adam! What is the capital of France?\ngemini-2.5-flash-lite >  Hi Adam! The capital of France is Paris.\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  Your name is Adam.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"üéâ **Success!** The agent remembered your name because both queries were part of the same session. The Runner automatically maintained the conversation history.\n\nBut there's a catch: `InMemorySessionService` is temporary. **Once the application stops, all conversation history is lost.** \n","metadata":{}},{"cell_type":"markdown","source":"### üõë (Optional) 2.6 Testing Agent's forgetfulness\n\n> To verify that the agent forgets the conversation, **restart the kernel**. Then, **run ALL the previous cells in this notebook EXCEPT the `run_session` in 2.5.**\n> \n> Now run the cell below. You'll see that the agent doesn't remember anything from the previous conversation.","metadata":{}},{"cell_type":"code","source":"# Run this cell after restarting the kernel. All this history will be gone...\nawait run_session(\n    runner,\n    [\"What did I ask you about earlier?\", \"And remind me, what's my name?\"],\n    \"stateful-agentic-session\",\n)  # Note, we are using same session name","metadata":{"lines_to_next_cell":2,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### The Problem\n\nSession information is not persistent (i.e., meaningful conversations are lost). While this is advantageous in testing environments, **in the real world, a user should be able to refer from past and resume conversations.** To achieve this, we must persist information. ","metadata":{}},{"cell_type":"markdown","source":"---\n## üìà Section 3: Persistent Sessions with `DatabaseSessionService`\n\nWhile `InMemorySessionService` is great for prototyping, real-world applications need conversations to survive restarts, crashes, and deployments. Let's level up to persistent storage!\n\n### 3.1 Choosing the Right SessionService\n\nADK provides different SessionService implementations for different needs:\n\n| Service | Use Case | Persistence | Best For |\n|---------|----------|-------------|----------|\n| **InMemorySessionService** | Development & Testing | ‚ùå Lost on restart | Quick prototypes |\n| **DatabaseSessionService** | Self-managed apps | ‚úÖ Survives restarts | Small to medium apps |\n| **Agent Engine Sessions** | Production on GCP | ‚úÖ Fully managed | Enterprise scale |\n","metadata":{}},{"cell_type":"markdown","source":"### 3.2 Implementing Persistent Sessions\n\nLet's upgrade to `DatabaseSessionService` using SQLite. This gives us persistence without needing a separate database server for this demo.\n\nLet's create a `chatbot_agent` capable of having a conversation with the user.","metadata":{}},{"cell_type":"code","source":"# Step 1: Create the same agent (notice we use LlmAgent this time)\nchatbot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"A text chatbot with persistent memory\",\n)\n\n# Step 2: Switch to DatabaseSessionService\n# SQLite database will be created automatically\ndb_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\nsession_service = DatabaseSessionService(db_url=db_url)\n\n# Step 3: Create a new runner with persistent storage\nrunner = Runner(agent=chatbot_agent, app_name=APP_NAME, session_service=session_service)\n\nprint(\"‚úÖ Upgraded to persistent sessions!\")\nprint(f\"   - Database: my_agent_data.db\")\nprint(f\"   - Sessions will survive restarts!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:17:57.811198Z","iopub.execute_input":"2025-11-12T18:17:57.811567Z","iopub.status.idle":"2025-11-12T18:17:57.913313Z","shell.execute_reply.started":"2025-11-12T18:17:57.811540Z","shell.execute_reply":"2025-11-12T18:17:57.912533Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Upgraded to persistent sessions!\n   - Database: my_agent_data.db\n   - Sessions will survive restarts!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### 3.3 Test Run 1: Verifying Persistence\n\nIn this first test run, we'll start a new conversation with the session ID `test-db-session-01`. We will first introduce our name as 'Sam' and then ask a question. In the second turn, we will ask the agent for our name.\n\nSince we are using `DatabaseSessionService`, the agent should remember the name.\n\nAfter the conversation, we'll inspect the `my_agent_data.db` SQLite database directly to see how the conversation `events` (the user queries and model responses) are stored.\n","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner,\n    [\"Hi, I am Altman! What is the capital of the United States?\", \"Hello! What is my name?\"],\n    \"test-db-session-01\",\n)","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:18:01.671038Z","iopub.execute_input":"2025-11-12T18:18:01.671330Z","iopub.status.idle":"2025-11-12T18:18:02.865946Z","shell.execute_reply.started":"2025-11-12T18:18:01.671311Z","shell.execute_reply":"2025-11-12T18:18:02.865181Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: test-db-session-01\n\nUser > Hi, I am Altman! What is the capital of the United States?\ngemini-2.5-flash-lite >  Hello Altman! The capital of the United States is Washington, D.C.\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  Your name is Altman.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### üõë (Optional) 3.4 Test Run 2: Resuming a Conversation\n\n> ‚ÄºÔ∏è Now, let's repeat the test again, but this time, **let's stop this Kaggle Notebook's kernel and restart it again.**\n>\n> 1. Run all the previous cells in the notebook, **EXCEPT** the previous Section 3.3 (`run_session` cell).\n>\n> 2. Now, run the below cell with the **same session ID** (`test-db-session-01`).\n\nWe will ask a new question and then ask for our name again. **Because the session is loaded from the database, the agent should still remember** that our name is 'Sam' from the first test run. This demonstrates the power of persistent sessions.\n","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner,\n    [\"What is the capital of India?\", \"Hello! What is my name?\"],\n    \"test-db-session-01\",\n)","metadata":{"lines_to_next_cell":2,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.5 Let's verify that the session data is isolated\n\nAs mentioned earlier, a session is private conversation between an Agent and a User (i.e., two sessions do not share information). Let's run our `run_session` with a different session name `test-db-session-02` to confirm this.\n","metadata":{}},{"cell_type":"code","source":"await run_session(\n    runner, [\"Hello! What is my name?\"], \"test-db-session-02\"\n)  # Note, we are using new session name","metadata":{"lines_to_next_cell":2,"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:18:10.611905Z","iopub.execute_input":"2025-11-12T18:18:10.612244Z","iopub.status.idle":"2025-11-12T18:18:11.202321Z","shell.execute_reply.started":"2025-11-12T18:18:10.612219Z","shell.execute_reply":"2025-11-12T18:18:11.201327Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: test-db-session-02\n\nUser > Hello! What is my name?\ngemini-2.5-flash-lite >  I do not have access to your personal information, including your name. I am a large language model, and my purpose is to assist you with your requests in a safe and helpful manner.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 3.6 How are the events stored in the Database?\n\nSince we are using a sqlite DB to store information, let's have a quick peek to see how information is stored.","metadata":{}},{"cell_type":"code","source":"import sqlite3\n\ndef check_data_in_db():\n    with sqlite3.connect(\"my_agent_data.db\") as connection:\n        cursor = connection.cursor()\n        result = cursor.execute(\n            \"select app_name, session_id, author, content from events\"\n        )\n        print([_[0] for _ in result.description])\n        for each in result.fetchall():\n            print(each)\n\n\ncheck_data_in_db()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:19:46.011526Z","iopub.execute_input":"2025-11-12T18:19:46.012167Z","iopub.status.idle":"2025-11-12T18:19:46.018488Z","shell.execute_reply.started":"2025-11-12T18:19:46.012140Z","shell.execute_reply":"2025-11-12T18:19:46.017555Z"}},"outputs":[{"name":"stdout","text":"['app_name', 'session_id', 'author', 'content']\n('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hi, I am Altman! What is the capital of the United States?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Hello Altman! The capital of the United States is Washington, D.C.\"}], \"role\": \"model\"}')\n('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Altman.\"}], \"role\": \"model\"}')\n('default', 'test-db-session-02', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n('default', 'test-db-session-02', 'text_chat_bot', '{\"parts\": [{\"text\": \"I do not have access to your personal information, including your name. I am a large language model, and my purpose is to assist you with your requests in a safe and helpful manner.\"}], \"role\": \"model\"}')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"---\n## ‚è≥ Section 4: Context Compaction\n\nAs you can see, all the events are stored in full in the session Database, and this quickly adds up. For a long, complex task, this list of events can become very large, leading to slower performance and higher costs.\n\nBut what if we could automatically summarize the past? Let's use ADK's **Context Compaction** feature to see **how to automatically reduce the context that's stored in the Session.**","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/context-compaction.png\" width=\"1400\" alt=\"Context compaction\">","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Create an App for the agent\n\nTo enable this feature, let's use the same `chatbot_agent` we created in Section 3.2. \n\nThe first step is to create an object called `App`. We'll give it a name and pass in our chatbot_agent. \n\nWe'll also create a new config to do the Context Compaction. This **`EventsCompactionConfig`** defines two key variables:\n\n- **compaction_interval**: Asks the Runner to compact the history after every `n` conversations\n- **overlap_size**: Defines the number of previous conversations to retain for overlap\n\nWe'll then provide this app to the Runner.\n","metadata":{}},{"cell_type":"code","source":"# Re-define our app with Events Compaction enabled\nresearch_app_compacting = App(\n    name=\"research_app_compacting\",\n    root_agent=chatbot_agent,\n    # This is the new part!\n    events_compaction_config=EventsCompactionConfig(\n        compaction_interval=3,  # Trigger compaction every 3 invocations\n        overlap_size=1,  # Keep 1 previous turn for context\n    ),\n)\n\ndb_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\nsession_service = DatabaseSessionService(db_url=db_url)\n\n# Create a new runner for our upgraded app\nresearch_runner_compacting = Runner(\n    app=research_app_compacting, session_service=session_service\n)\n\n\nprint(\"‚úÖ Research App upgraded with Events Compaction!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:21:16.471077Z","iopub.execute_input":"2025-11-12T18:21:16.471453Z","iopub.status.idle":"2025-11-12T18:21:16.480772Z","shell.execute_reply.started":"2025-11-12T18:21:16.471411Z","shell.execute_reply":"2025-11-12T18:21:16.479865Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Research App upgraded with Events Compaction!\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_48/3773147741.py:6: UserWarning: [EXPERIMENTAL] EventsCompactionConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  events_compaction_config=EventsCompactionConfig(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### 4.2 Running the Demo\n\nNow, let's have a conversation that is long enough to trigger the compaction. When you run the cell below, the output will look like a normal conversation. However, because we configured our `App`, a compaction process will run silently in the background after the 3rd invocation.\n\nIn the next step, we'll prove that it happened.","metadata":{}},{"cell_type":"code","source":"# Turn 1\nawait run_session(\n    research_runner_compacting,\n    \"What is the latest news about AI in healthcare?\",\n    \"compaction_demo\",\n)\n\n# Turn 2\nawait run_session(\n    research_runner_compacting,\n    \"Are there any new developments in drug discovery?\",\n    \"compaction_demo\",\n)\n\n# Turn 3 - Compaction should trigger after this turn!\nawait run_session(\n    research_runner_compacting,\n    \"Tell me more about the second development you found.\",\n    \"compaction_demo\",\n)\n\n# Turn 4\nawait run_session(\n    research_runner_compacting,\n    \"Who are the main companies involved in that?\",\n    \"compaction_demo\",\n)","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:22:10.091699Z","iopub.execute_input":"2025-11-12T18:22:10.092047Z","iopub.status.idle":"2025-11-12T18:22:30.133339Z","shell.execute_reply.started":"2025-11-12T18:22:10.092024Z","shell.execute_reply":"2025-11-12T18:22:30.132248Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: compaction_demo\n\nUser > What is the latest news about AI in healthcare?\ngemini-2.5-flash-lite >  The field of AI in healthcare is incredibly dynamic, with new developments emerging almost daily. To give you the most up-to-date information, I'll focus on some of the *latest significant trends and recent breakthroughs* that have been making waves.\n\nHere are some of the key areas and recent news:\n\n**1. Advancements in Drug Discovery and Development:**\n*   **Accelerated Drug Design:** AI is revolutionizing how new drugs are discovered. Recent news highlights AI models that can predict the efficacy and potential side effects of drug candidates much faster than traditional methods. Companies are using AI to identify novel drug targets and design molecules with desired properties.\n*   **Personalized Medicine:** AI is crucial for analyzing vast amounts of patient data (genomics, lifestyle, medical history) to identify which treatments will be most effective for individual patients. This is leading to more targeted therapies, especially in oncology.\n\n**2. AI in Medical Imaging and Diagnostics:**\n*   **Improved Accuracy and Speed:** AI algorithms are becoming incredibly adept at analyzing medical images (X-rays, CT scans, MRIs, pathology slides). Recent research shows AI matching or even surpassing human radiologists in detecting certain conditions like diabetic retinopathy, skin cancer, and early signs of Alzheimer's.\n*   **Early Disease Detection:** The ability of AI to spot subtle patterns in images that might be missed by the human eye is a major focus. This is leading to earlier diagnoses, which often translates to better patient outcomes.\n\n**3. AI-Powered Predictive Analytics:**\n*   **Forecasting Patient Deterioration:** Hospitals are increasingly using AI to predict which patients are at high risk of deteriorating or developing complications (like sepsis or cardiac arrest). This allows for proactive interventions and can save lives.\n*   **Resource Optimization:** AI is being used to predict patient flow, hospital bed availability, and staffing needs, helping healthcare systems operate more efficiently and reduce costs.\n\n**4. Generative AI in Healthcare:**\n*   **Clinical Documentation and Summarization:** Large Language Models (LLMs) like the one I'm based on are being explored and implemented for tasks like generating clinical notes, summarizing patient records, and even drafting responses to patient queries. This can significantly reduce the administrative burden on clinicians.\n*   **Medical Education and Training:** Generative AI can create realistic patient scenarios for training medical students and professionals, providing safe and effective learning experiences.\n\n**5. AI for Mental Health:**\n*   **Therapeutic Chatbots:** AI-powered chatbots are being developed to provide accessible mental health support, offering cognitive behavioral therapy techniques, mindfulness exercises, and emotional support.\n*   **Early Identification of Mental Health Conditions:** AI can analyze patterns in text, speech, and even social media activity to help identify individuals who may be struggling with mental health issues.\n\n**Challenges and Considerations:**\nDespite these exciting advancements, it's important to note that the integration of AI in healthcare still faces hurdles:\n*   **Data Privacy and Security:** Protecting sensitive patient information is paramount.\n*   **Regulatory Approval:** Ensuring AI tools are safe, effective, and ethical requires robust regulatory frameworks.\n*   **Bias in AI:** AI models trained on biased data can perpetuate or even amplify existing health disparities.\n*   **Clinician Adoption and Trust:** Building trust and ensuring healthcare professionals are comfortable and proficient in using AI tools is crucial.\n*   **Integration with Existing Systems:** Seamlessly integrating new AI technologies into complex hospital IT infrastructures can be challenging.\n\n**Where to find the latest news:**\nFor the absolute latest, I would recommend checking reputable sources like:\n*   **Medical Journals:** JAMA, The Lancet, Nature Medicine, NEJM.\n*   **Healthcare Technology News Sites:** FierceHealthcare, MobiHealthNews, Healthcare IT News.\n*   **Major Tech and Science Publications:** TechCrunch (often has a healthcare section), MIT Technology Review, Scientific American.\n*   **Conferences and Reports:** Look for summaries and news from major AI and healthcare conferences (e.g., HIMSS, NeurIPS).\n\nThe pace of innovation is rapid, so what's \"latest\" can change by the week! If you have a specific area of AI in healthcare you're interested in, let me know, and I can try to provide more targeted information.\n\n ### Session: compaction_demo\n\nUser > Are there any new developments in drug discovery?\ngemini-2.5-flash-lite >  Yes, there are continuous and exciting new developments in drug discovery, largely driven by advancements in AI and related technologies. Here are some of the most prominent and recent trends:\n\n**1. AI-Driven Molecule Design and Optimization:**\n*   **Generative AI for Novel Compounds:** This is a huge area. Instead of screening existing libraries, AI models (often generative adversarial networks or transformer models) are now being used to *design entirely new molecules* from scratch, with specific desired properties (e.g., binding affinity to a target, solubility, low toxicity). Recent breakthroughs show AI generating molecules that have then been synthesized and shown to be effective in preclinical studies.\n*   **Predictive Modeling for Properties:** AI is getting better at predicting various properties of a potential drug molecule early in the process. This includes pharmacokinetic (how the body processes the drug) and pharmacodynamic (how the drug affects the body) properties, as well as potential off-target effects and toxicity. This saves significant time and resources by filtering out unpromising candidates sooner.\n\n**2. Advanced Target Identification and Validation:**\n*   **Genomics and Proteomics Integration:** AI is adept at sifting through massive datasets from genomics, transcriptomics, and proteomics. Recent work focuses on using AI to identify novel biological targets implicated in diseases that were previously difficult to pinpoint.\n*   **Understanding Disease Mechanisms:** AI is helping researchers unravel complex biological pathways and identify key nodes or targets that, if modulated, could effectively treat a disease. This goes beyond just identifying a protein and looks at the entire system.\n\n**3. AI in Clinical Trial Optimization:**\n*   **Patient Stratification:** AI can analyze patient data to identify subgroups who are most likely to respond to a particular drug. This leads to more efficient clinical trials by enrolling the right patients.\n*   **Predicting Trial Success/Failure:** AI models are being developed to predict the likelihood of success for a clinical trial based on preclinical data, trial design, and historical data.\n*   **Decentralized Clinical Trials:** While not purely AI, AI plays a role in analyzing data from remote monitoring devices and wearables used in decentralized trials, making them more efficient and patient-centric.\n\n**4. Repurposing Existing Drugs:**\n*   **AI for Drug Repositioning:** AI algorithms can analyze vast databases of existing drugs, their known mechanisms of action, and disease pathways to identify drugs that might be effective against new indications. This is a faster and often cheaper route to new treatments because the safety profiles of these drugs are already known. Recent examples include AI identifying existing antivirals for new viral threats.\n\n**5. Novel Modalities and Technologies:**\n*   **RNA Therapeutics:** AI is playing a role in designing and optimizing RNA-based therapies (like mRNA vaccines and therapeutics) by predicting RNA structure, stability, and immunogenicity.\n*   **CRISPR and Gene Editing:** AI is being used to improve the precision and efficacy of gene editing tools by predicting off-target edits and designing optimal guide RNAs.\n\n**Key Examples and Trends in News:**\n*   **Partnerships:** You'll see a lot of news about partnerships between traditional pharmaceutical companies and AI-driven biotech startups (e.g., Recursion Pharmaceuticals, Exscientia, Insilico Medicine). These collaborations aim to leverage AI for faster discovery.\n*   **FDA Approvals:** While AI doesn't get directly approved, drugs discovered or developed with significant AI involvement are starting to enter clinical trials and, in some cases, reach regulatory approval. Keep an eye on news from regulatory bodies like the FDA.\n*   **Specific Disease Areas:** AI is making significant strides in areas like oncology, neurodegenerative diseases (Alzheimer's, Parkinson's), and infectious diseases.\n\nIn essence, AI is moving drug discovery from a lengthy, often serendipitous process to a more **predictive, design-driven, and data-intensive endeavor**. The focus is on speed, efficiency, and the creation of more precise and personalized therapies.\n\n ### Session: compaction_demo\n\nUser > Tell me more about the second development you found.\ngemini-2.5-flash-lite >  You're referring to the second development I mentioned in drug discovery: **AI in Medical Imaging and Diagnostics**.\n\nThis area is experiencing rapid advancements, and it's crucial because accurate and timely diagnosis is the foundation for effective treatment. Here's a deeper dive into what's happening:\n\n**How AI is Revolutionizing Medical Imaging and Diagnostics:**\n\n1.  **Enhanced Image Analysis and Detection:**\n    *   **Radiology:** AI algorithms are being trained on vast datasets of X-rays, CT scans, and MRIs to identify subtle abnormalities that might be missed by the human eye.\n        *   **Examples:** Detecting early signs of lung cancer on chest X-rays, identifying small tumors in mammograms, spotting micro-aneurysms in retinal scans (diabetic retinopathy), and flagging potential strokes on CT scans.\n        *   **Recent Trends:** AI is moving beyond just \"finding anomalies\" to providing more detailed quantitative analysis ‚Äì measuring tumor size with high precision, assessing the extent of disease, and tracking changes over time.\n    *   **Pathology:** AI is transforming the analysis of tissue slides. Pathologists often examine hundreds of slides to diagnose cancer and grade its severity. AI can automate parts of this process.\n        *   **Examples:** Identifying cancerous cells in prostate or breast biopsies, grading tumor aggressiveness, and quantifying biomarkers within cells.\n        *   **Recent Trends:** AI is helping pathologists make more objective and reproducible diagnoses, reducing inter-observer variability.\n    *   **Dermatology:** AI models are becoming highly proficient at analyzing images of skin lesions to differentiate between benign moles and potentially cancerous melanomas.\n        *   **Examples:** Mobile apps and clinical tools are emerging that can analyze skin photos for early detection of skin cancer.\n\n2.  **Early Disease Prediction and Risk Assessment:**\n    *   **Beyond Detection:** AI can analyze imaging data in conjunction with other patient information (genetics, medical history) to predict a patient's risk of developing certain diseases in the future.\n    *   **Examples:** Predicting the likelihood of cardiovascular events based on CT scans of arteries, or forecasting the progression of Alzheimer's disease based on brain MRI scans.\n\n3.  **Workflow Optimization and Efficiency:**\n    *   **Prioritization:** AI can flag critical cases in imaging queues, ensuring that patients with urgent conditions are seen and diagnosed faster.\n    *   **Reduced Radiologist Burden:** By automating initial screenings or highlighting areas of concern, AI can help radiologists focus their expertise on the most complex cases, improving throughput and reducing burnout.\n    *   **Image Reconstruction and Quality Improvement:** AI can be used to reconstruct images from less data, potentially reducing scan times or radiation exposure, and to enhance the quality of images acquired under challenging conditions.\n\n**Key Developments and News:**\n\n*   **FDA Approvals:** The FDA has been approving AI-powered medical devices at an increasing rate. This signifies growing confidence in the safety and efficacy of these tools. Many of these approvals are for specific diagnostic tasks, such as detecting pulmonary embolisms or identifying intracranial hemorrhages.\n*   **Integration into PACS Systems:** AI tools are increasingly being integrated into Picture Archiving and Communication Systems (PACS), the software used by radiologists to view and manage medical images. This makes them more accessible in daily clinical practice.\n*   **\"AI as a Co-Pilot\":** The trend is moving towards AI acting as an assistant or \"co-pilot\" to clinicians, rather than replacing them entirely. The AI flags potential findings, provides quantitative data, and offers a second opinion, but the final diagnosis and treatment plan rest with the human expert.\n*   **Multimodal AI:** Newer developments involve AI that can integrate information from different imaging modalities (e.g., combining PET and MRI data) or combine imaging data with other types of patient data (genomics, electronic health records) for a more comprehensive diagnostic picture.\n\n**Challenges:**\n\n*   **Data Bias:** Ensuring that AI models are trained on diverse datasets representing different demographics is critical to avoid biased diagnoses.\n*   **Regulatory Hurdles:** While improving, the pathway for AI device approval can still be complex.\n*   **Clinical Validation:** Rigorous real-world clinical validation is essential to demonstrate the actual benefit and safety of AI tools.\n*   **Interoperability:** Integrating AI into existing hospital IT infrastructure can be technically challenging.\n\nIn summary, AI is dramatically enhancing the precision, speed, and accessibility of medical diagnostics, with a particular impact on the interpretation of medical images. This \"second development\" is fundamental to improving patient care across a wide range of conditions.\n\n ### Session: compaction_demo\n\nUser > Who are the main companies involved in that?\ngemini-2.5-flash-lite >  The landscape of companies involved in AI for medical imaging and diagnostics is diverse, ranging from established giants in medical technology to innovative startups. Here are some of the main players and categories of companies:\n\n**1. Large Medical Technology and Imaging Companies:**\n\nThese companies are integrating AI into their existing imaging hardware and software platforms.\n*   **GE Healthcare:** A major player developing AI solutions for various imaging modalities, including MRI, CT, and ultrasound. They focus on improving image quality, workflow efficiency, and diagnostic insights.\n*   **Siemens Healthineers:** Similar to GE, Siemens Healthineers is investing heavily in AI for their imaging devices. They offer AI-powered solutions for radiology, cardiology, and other specialties to enhance image analysis and detect diseases earlier.\n*   **Philips:** Philips is also a significant player, integrating AI into its diagnostic imaging portfolio to support clinicians in interpreting images, improving operational efficiency, and enabling personalized care.\n*   **Canon Medical Systems:** They are developing AI applications for their CT, MRI, and ultrasound systems, focusing on improving diagnostic accuracy and speed.\n*   **Fujifilm Healthcare:** Fujifilm has been active in AI for medical imaging, particularly in areas like mammography and CT, aiming to support early cancer detection and diagnosis.\n\n**2. Dedicated AI Imaging Software Companies (Startups and Established AI Firms):**\n\nThese companies focus specifically on developing AI algorithms and software for analyzing medical images, often acting as third-party solutions that can integrate with existing imaging hardware.\n*   **Viz.ai:** Known for its AI-powered platform that detects and alerts clinicians to time-sensitive conditions like stroke and pulmonary embolism, significantly speeding up diagnosis and treatment.\n*   **Aidoc:** Another prominent company offering an AI platform that analyzes medical images across various modalities (CT, X-ray, MRI) to flag suspected critical conditions, helping prioritize radiologist workflow.\n*   **Paige:** A leader in AI-powered digital pathology. Paige received FDA clearance for its AI tool to help pathologists detect prostate cancer.\n*   **Arterys:** Offers AI-powered software solutions for cardiology, oncology, and pulmonology, providing advanced image analysis and quantitative insights.\n*   **Qure.ai:** Develops AI solutions for X-ray and CT scans, focusing on areas like chest X-rays for tuberculosis, lung nodule detection, and head CT analysis.\n*   **RadLogics:** Provides AI-powered software for analyzing a wide range of medical images to detect abnormalities and improve radiologist efficiency.\n*   **Kensho Health (formerly Kensho AI):** While Kensho is a broader AI firm, they have been involved in healthcare AI applications, including potentially imaging analysis.\n*   **Zebra Medical Vision (now part of Nanox):** Was a significant player in AI for radiology, offering solutions for detecting various conditions from X-rays and CT scans. Its acquisition by Nanox signals integration into a broader diagnostic ecosystem.\n\n**3. Cloud Providers and AI Infrastructure Companies:**\n\nWhile not directly developing diagnostic AI, these companies provide the underlying cloud infrastructure and AI development tools that enable many of the imaging AI solutions.\n*   **Google Cloud (Google Health):** Has been actively involved in medical imaging AI research and partnerships, developing tools and offering cloud services for healthcare AI development.\n*   **Amazon Web Services (AWS):** Provides cloud infrastructure and AI/ML services (like Amazon Comprehend Medical, which can analyze clinical text, and SageMaker for building ML models) that are essential for training and deploying medical imaging AI.\n*   **Microsoft Azure:** Offers similar cloud and AI services that support healthcare companies in their AI initiatives, including medical imaging.\n\n**4. Academic Institutions and Research Collaborations:**\n\nMany breakthroughs originate from academic research. Universities and hospitals often collaborate with industry partners to develop and validate new AI imaging algorithms.\n\n**Key Trends in Company Involvement:**\n\n*   **Acquisitions:** Larger med-tech companies are acquiring promising AI imaging startups to integrate their technologies into their product portfolios.\n*   **Partnerships:** Collaborations between imaging hardware manufacturers, AI software developers, and healthcare providers are common to ensure practical application and validation.\n*   **Focus on Specific Use Cases:** Companies often specialize in particular imaging modalities (e.g., mammography, CT) or specific disease areas (e.g., stroke, cancer) to build deep expertise.\n\nThis is not an exhaustive list, as new companies and solutions are emerging continuously. The field is characterized by intense innovation and collaboration.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### 4.3 Verifying Compaction in the Session History\n\nThe conversation above looks normal, but the history has been changed behind the scenes. How can we prove it?\n\nWe can inspect the `events` list from our session. The compaction process **doesn't delete old events; it replaces them with a single, new `Event` that contains the summary.** Let's find it.","metadata":{}},{"cell_type":"code","source":"# Get the final session state\nfinal_session = await session_service.get_session(\n    app_name=research_runner_compacting.app_name,\n    user_id=USER_ID,\n    session_id=\"compaction_demo\",\n)\n\nprint(\"--- Searching for Compaction Summary Event ---\")\nfound_summary = False\nfor event in final_session.events:\n    # Compaction events have a 'compaction' attribute\n    if event.actions and event.actions.compaction:\n        print(\"\\n‚úÖ SUCCESS! Found the Compaction Event:\")\n        print(f\"  Author: {event.author}\")\n        print(f\"\\n Compacted information: {event}\")\n        found_summary = True\n        break\n\nif not found_summary:\n    print(\n        \"\\n‚ùå No compaction event found. Try increasing the number of turns in the demo.\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:23:25.872068Z","iopub.execute_input":"2025-11-12T18:23:25.872409Z","iopub.status.idle":"2025-11-12T18:23:25.884245Z","shell.execute_reply.started":"2025-11-12T18:23:25.872386Z","shell.execute_reply":"2025-11-12T18:23:25.883345Z"}},"outputs":[{"name":"stdout","text":"--- Searching for Compaction Summary Event ---\n\n‚úÖ SUCCESS! Found the Compaction Event:\n  Author: user\n\n Compacted information: model_version=None content=None grounding_metadata=None partial=None turn_complete=None finish_reason=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None live_session_resumption_update=None input_transcription=None output_transcription=None avg_logprobs=None logprobs_result=None cache_metadata=None citation_metadata=None invocation_id='e7676e13-d1c7-4cf4-9a2d-795e92e41e40' author='user' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction={'start_timestamp': 1762971730.129355, 'end_timestamp': 1762971739.529176, 'compacted_content': {'parts': [{'function_call': None, 'code_execution_result': None, 'executable_code': None, 'file_data': None, 'function_response': None, 'inline_data': None, 'text': 'The conversation began with the user asking for the latest news on AI in healthcare. The AI agent provided a comprehensive overview of recent developments, categorizing them into advancements in drug discovery, medical imaging/diagnostics, predictive analytics, generative AI, and AI for mental health. The agent also highlighted key challenges and recommended sources for staying updated.\\n\\nThe user then inquired specifically about new developments in drug discovery. The AI agent detailed advancements such as AI-driven molecule design and optimization, enhanced target identification and validation, AI in clinical trial optimization, drug repurposing using AI, and AI\\'s role in novel modalities like RNA therapeutics and gene editing. The agent noted the trend of partnerships between pharmaceutical companies and AI biotechs and the increasing use of AI in drug discovery for specific disease areas.\\n\\nFinally, the user asked for more information on the \"second development\" mentioned earlier, which the AI identified as **AI in Medical Imaging and Diagnostics**. The agent elaborated on how AI is revolutionizing image analysis for radiology, pathology, and dermatology by improving detection accuracy, enabling early disease prediction, and optimizing clinical workflows. Key developments highlighted included increasing FDA approvals for AI medical devices, integration into PACS systems, the concept of AI as a \"co-pilot,\" and the rise of multimodal AI. The agent also reiterated challenges such as data bias, regulatory hurdles, clinical validation, and interoperability.', 'thought': None, 'thought_signature': None, 'video_metadata': None}], 'role': 'model'}}, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None) long_running_tool_ids=set() branch=None id='57f255e0-e00f-4a92-bb65-31576ca6f9d5' timestamp=1762971746.153006\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### 4.4 What you've accomplished: Automatic Context Management\n\nYou just found the proof! The presence of that special summary `Event` in your session's history is the tangible result of the compaction process.\n\n**Let's recap what you just witnessed:**\n\n1.  **Silent Operation**: You ran a standard conversation, and from the outside, nothing seemed different.\n2.  **Background Compaction**: Because you configured the `App` with `EventsCompactionConfig`, the ADK `Runner` automatically monitored the conversation length. Once the threshold was met, it triggered the summarization process in the background.\n3.  **Verified Result**: By inspecting the session's events, you found the summary that the LLM generated. This summary now replaces the older, more verbose turns in the agent's active context.\n\n**For all future turns in this conversation, the agent will be given this concise summary instead of the full history.** This saves costs, improves performance, and helps the agent stay focused on what's most important.\n","metadata":{}},{"cell_type":"markdown","source":"### 4.5 More Context Engineering options in ADK\n\n#### üëâ Custom Compaction\nIn this example, we used ADK's default summarizer. For more advanced use cases, you can provide your own by defining a custom `SlidingWindowCompactor` and passing it to the config. This allows you to control the summarization prompt or even use a different, specialized LLM for the task. You can read more about it in the [official documentation](https://google.github.io/adk-docs/context/compaction/).\n\n#### üëâ Context Caching\nADK also provides **Context Caching** to help reduce the token size of the static instructions that are fed to the LLM by caching the request data. Read more about it [here](https://google.github.io/adk-docs/context/caching/).","metadata":{}},{"cell_type":"markdown","source":"### The Problem\n\nWhile we can do Context Compaction and use a database to resume a session, we face new challenges now. In some cases, **we have key information or preferences that we want to share across other sessions.** \n\nIn these scenarios, instead of sharing the entire session history, transferring information from a few key variables can improve the session experience. Let's see how to do it!","metadata":{}},{"cell_type":"markdown","source":"---\n## ü§ù Section 5: Working with Session State\n\n### 5.1 Creating custom tools for Session state management\n\nLet's explore how to manually manage session state through custom tools. In this example, we'll identify a **transferable characteristic**, like a user's name and their country, and create tools to capture and save it.\n\n**Why This Example?**\n\nThe username is a perfect example of information that:\n\n- Is introduced once but referenced multiple times\n- Should persist throughout a conversation\n- Represents a user-specific characteristic that enhances personalization\n\nHere, for demo purposes, we'll create two tools that can store and retrieve user name and country from the Session State. **Note that all tools have access to the `ToolContext` object.** You don't have to create separate tools for each piece of information you want to share. ","metadata":{}},{"cell_type":"code","source":"# Define scope levels for state keys (following best practices)\nUSER_NAME_SCOPE_LEVELS = (\"temp\", \"user\", \"app\")\n\n\n# This demonstrates how tools can write to session state using tool_context.\n# The 'user:' prefix indicates this is user-specific data.\ndef save_userinfo(\n    tool_context: ToolContext, user_name: str, country: str\n) -> Dict[str, Any]:\n    \"\"\"\n    Tool to record and save user name and country in session state.\n\n    Args:\n        user_name: The username to store in session state\n        country: The name of the user's country\n    \"\"\"\n    # Write to session state using the 'user:' prefix for user data\n    tool_context.state[\"user:name\"] = user_name\n    tool_context.state[\"user:country\"] = country\n\n    return {\"status\": \"success\"}\n\n\n# This demonstrates how tools can read from session state.\ndef retrieve_userinfo(tool_context: ToolContext) -> Dict[str, Any]:\n    \"\"\"\n    Tool to retrieve user name and country from session state.\n    \"\"\"\n    # Read from session state\n    user_name = tool_context.state.get(\"user:name\", \"Username not found\")\n    country = tool_context.state.get(\"user:country\", \"Country not found\")\n\n    return {\"status\": \"success\", \"user_name\": user_name, \"country\": country}\n\n\nprint(\"‚úÖ Tools created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:25:59.674872Z","iopub.execute_input":"2025-11-12T18:25:59.675242Z","iopub.status.idle":"2025-11-12T18:25:59.682845Z","shell.execute_reply.started":"2025-11-12T18:25:59.675215Z","shell.execute_reply":"2025-11-12T18:25:59.681793Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Tools created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"**Key Concepts:**\n- Tools can access `tool_context.state` to read/write session state\n- Use descriptive key prefixes (`user:`, `app:`, `temp:`) for organization\n- State persists across conversation turns within the same session","metadata":{}},{"cell_type":"markdown","source":"### 5.2 Creating an Agent with Session State Tools\n\nNow let's create a new agent that has access to our session state management tools:","metadata":{}},{"cell_type":"code","source":"# Configuration\nAPP_NAME = \"default\"\nUSER_ID = \"default\"\nMODEL_NAME = \"gemini-2.5-flash-lite\"\n\n# Create an agent with session state tools\nroot_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"text_chat_bot\",\n    description=\"\"\"A text chatbot.\n    Tools for managing user context:\n    * To record username and country when provided use `save_userinfo` tool. \n    * To fetch username and country when required use `retrieve_userinfo` tool.\n    \"\"\",\n    tools=[save_userinfo, retrieve_userinfo],  # Provide the tools to the agent\n)\n\n# Set up session service and runner\nsession_service = InMemorySessionService()\nrunner = Runner(agent=root_agent, session_service=session_service, app_name=\"default\")\n\nprint(\"‚úÖ Agent with session state tools initialized!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:26:43.859283Z","iopub.execute_input":"2025-11-12T18:26:43.859654Z","iopub.status.idle":"2025-11-12T18:26:43.867351Z","shell.execute_reply.started":"2025-11-12T18:26:43.859617Z","shell.execute_reply":"2025-11-12T18:26:43.866481Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Agent with session state tools initialized!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### 5.3 Testing Session State in Action\n\nLet's test how the agent uses session state to remember information across conversation turns:","metadata":{}},{"cell_type":"code","source":"# Test conversation demonstrating session state\nawait run_session(\n    runner,\n    [\n        \"Hi there, how are you doing today? What is my name?\",  # Agent shouldn't know the name yet\n        \"My name is Sam. I'm from Poland.\",  # Provide name - agent should save it\n        \"What is my name? Which country am I from?\",  # Agent should recall from session state\n    ],\n    \"state-demo-session\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:28:49.974661Z","iopub.execute_input":"2025-11-12T18:28:49.975011Z","iopub.status.idle":"2025-11-12T18:28:52.452050Z","shell.execute_reply.started":"2025-11-12T18:28:49.974983Z","shell.execute_reply":"2025-11-12T18:28:52.451283Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: state-demo-session\n\nUser > Hi there, how are you doing today? What is my name?\ngemini-2.5-flash-lite >  I'm doing well, thank you for asking! However, I don't have any information about your name. Could you please tell me what it is? \n\n\nUser > My name is Sam. I'm from Poland.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"gemini-2.5-flash-lite >  It is a pleasure to meet you, Sam! I will remember that you're from Poland.\n\nUser > What is my name? Which country am I from?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"gemini-2.5-flash-lite >  Your name is Sam and you are from Poland.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### 5.4 Inspecting Session State\n\nLet's directly inspect the session state to see what's stored:","metadata":{}},{"cell_type":"code","source":"# Retrieve the session and inspect its state\nsession = await session_service.get_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=\"state-demo-session\"\n)\n\nprint(\"Session State Contents:\")\nprint(session.state)\nprint(\"\\nüîç Notice the 'user:name' and 'user:country' keys storing our data!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:29:03.534367Z","iopub.execute_input":"2025-11-12T18:29:03.534718Z","iopub.status.idle":"2025-11-12T18:29:03.542062Z","shell.execute_reply.started":"2025-11-12T18:29:03.534695Z","shell.execute_reply":"2025-11-12T18:29:03.541289Z"}},"outputs":[{"name":"stdout","text":"Session State Contents:\n{'user:name': 'Sam', 'user:country': 'Poland'}\n\nüîç Notice the 'user:name' and 'user:country' keys storing our data!\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"### 5.5 Session State Isolation\n\nAs we've already seen, an important characteristic of session state is that it's isolated per session. Let's demonstrate this by starting a new session:","metadata":{}},{"cell_type":"code","source":"# Start a completely new session - the agent won't know our name\nawait run_session(\n    runner,\n    [\"Hi there, how are you doing today? What is my name?\"],\n    \"new-isolated-session\",\n)\n\n# Expected: The agent won't know the name because this is a different session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:29:20.774844Z","iopub.execute_input":"2025-11-12T18:29:20.775365Z","iopub.status.idle":"2025-11-12T18:29:21.497695Z","shell.execute_reply.started":"2025-11-12T18:29:20.775336Z","shell.execute_reply":"2025-11-12T18:29:21.496838Z"}},"outputs":[{"name":"stdout","text":"\n ### Session: new-isolated-session\n\nUser > Hi there, how are you doing today? What is my name?\ngemini-2.5-flash-lite >  Hello! I'm doing great, thank you for asking. I can't seem to recall your name at the moment. Could you please remind me? \n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### 5.6 Cross-Session State Sharing\n\nWhile sessions are isolated by default, you might notice something interesting. Let's check the state of our new session (`new-isolated-session`):","metadata":{}},{"cell_type":"code","source":"# Check the state of the new session\nsession = await session_service.get_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=\"new-isolated-session\"\n)\n\nprint(\"New Session State:\")\nprint(session.state)\n\n# Note: Depending on implementation, you might see shared state here.\n# This is where the distinction between session-specific and user-specific state becomes important.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:29:59.439306Z","iopub.execute_input":"2025-11-12T18:29:59.439647Z","iopub.status.idle":"2025-11-12T18:29:59.445517Z","shell.execute_reply.started":"2025-11-12T18:29:59.439622Z","shell.execute_reply":"2025-11-12T18:29:59.444460Z"}},"outputs":[{"name":"stdout","text":"New Session State:\n{'user:name': 'Sam', 'user:country': 'Poland'}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"---\n\n## üßπ Cleanup","metadata":{}},{"cell_type":"code","source":"# Clean up any existing database to start fresh (if Notebook is restarted)\nimport os\n\nif os.path.exists(\"my_agent_data.db\"):\n    os.remove(\"my_agent_data.db\")\nprint(\"‚úÖ Cleaned up old database files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:30:37.055119Z","iopub.execute_input":"2025-11-12T18:30:37.056257Z","iopub.status.idle":"2025-11-12T18:30:37.061960Z","shell.execute_reply.started":"2025-11-12T18:30:37.056217Z","shell.execute_reply":"2025-11-12T18:30:37.061018Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Cleaned up old database files\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"---\n## üìä Summary\n\nüéâ Congratulations! You've learned the fundamentals of building stateful AI agents:\n\n- ‚úÖ **Context Engineering** - You understand how to assemble context for LLMs using Context Compaction\n- ‚úÖ **Sessions & Events** - You can maintain conversation history across multiple turns\n- ‚úÖ **Persistent Storage** - You know how to make conversations survive restarts\n- ‚úÖ **Session State** - You can track structured data during conversations\n- ‚úÖ **Manual State Management** - You've experienced both the power and limitations of manual approaches\n- ‚úÖ **Production Considerations** - You're ready to handle real-world challenges\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You did it üéâ\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [ADK Documentation](https://google.github.io/adk-docs/)\n- [ADK Sessions](https://google.github.io/adk-docs/)\n- [ADK Session-State](https://medium.com/google-cloud/2-minute-adk-manage-context-efficiently-with-artifacts-6fcc6683d274)\n- [ADK Session Compaction](https://google.github.io/adk-docs/context/compaction/#define-compactor)\n\n### üéØ Next Steps - Long Term Memory Systems (Part 2)\n\n#### Why do we need memory?\nIn this notebook, we manually identified a couple characteristic (username and country) and built tools to manage it. But real conversations involve hundreds of such characteristics:\n- User preferences and habits\n- Past interactions and their outcomes\n- Domain knowledge and expertise levels\n- Communication styles and patterns\n- Contextual relationships between topics\n\n**The Memory System in ADK automates this entire process**, making it a valuable asset for building truly Context-Aware Agents that can accommodate any user's current and future needs.\n\nIn the next notebook (Part 2: Memory Management), you'll learn how to:\n- Enable automatic memory extraction from conversations\n- Build agents that learn and adapt over time\n- Create truly personalized experiences at scale\n- Manage long-term knowledge across sessions\n\nReady to transform your manual state management into an intelligent, automated Memory system? Let's continue to Part 2!","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Sampath M](https://www.linkedin.com/in/msampathkumar/) |","metadata":{}}]}